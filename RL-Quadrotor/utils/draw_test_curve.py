import matplotlib.pyplot as plt
import numpy as np

# test scores during training process extracted from logs.
# ACTOR_LR = 0.0001  # Actor网络更新的 learning rate
# CRITIC_LR = 0.01   # Critic网络更新的 learning rate
score = np.array([-762.7086458010807,
                  -829.7039667937222,
                  -852.4363611066034,
                  -890.2888413747776,
                  -944.8511112290838,
                  -784.0590945328481,
                  -855.8486625998139,
                  -799.8168379567369,
                  -912.232263850097,
                  -916.3884415020957,
                  -662.8122111417573,
                  -867.1186427192512,
                  -850.6192040495522,
                  -813.0204828788839,
                  -866.1568347984497,
                  -899.8092394086783,
                  -810.002053436185,
                  -834.2204623337742,
                  -678.3010998954585,
                  -597.7732324663257,
                  -530.1607985418766,
                  -452.0446451767078,
                  -390.4326686014964,
                  -325.3508323530837,
                  -199.32448169918712,
                  -59.3122072805849,
                  -22.073456152122567,
                  -20.83232294219092,
                  -21.181337010550315,
                  -21.038376223579])

episode = np.array([1000,
                    10000,
                    20000,
                    30000,
                    40000,
                    50000,
                    60000,
                    70000,
                    80000,
                    90000,
                    100000,
                    110000,
                    120000,
                    130000,
                    140000,
                    150000,
                    160000,
                    170000,
                    180000,
                    190000,
                    200000,
                    210000,
                    220000,
                    230000,
                    240000,
                    250000,
                    260000,
                    270000,
                    280000,
                    290000])

plt.plot(episode, score, color='red', label='test')
plt.title('Reward History 0.0001_0.01_2_2900000')
plt.legend()
plt.savefig('../fig_dir/test_0.0001_0.01_2_2900000.png')
plt.show()
